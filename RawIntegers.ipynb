{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import csv\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "from utils_train import train, test, fit\n",
    "\n",
    "\n",
    "np.random.seed(123)\n",
    "learning_rate = 0.005\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8732\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "def csvToAudioList(filename,sourceDir):\n",
    "    dataList = []\n",
    "    with open(filename, \"rt\") as csvfile:\n",
    "        lines = csv.reader(csvfile)\n",
    "        dataList = list(lines)\n",
    "        dataList.pop(0)\n",
    "        #delete\n",
    "        #dataList = dataList[1800:2000]\n",
    "        #\n",
    "\n",
    "        audDataset = []\n",
    "        labelDataset = []\n",
    "        print(len(dataList))\n",
    "        for x in dataList:\n",
    "            audData, freq = librosa.load(sourceDir + x[5] +\"/\"+ x[0])\n",
    "            if(len(audData) != 88200):\n",
    "                audData = fillWithZeros(audData)\n",
    "            audDataset.append(audData)\n",
    "            labelDataset.append(labelTrans(x[7]))\n",
    "        print(\"Finished\")\n",
    "\n",
    "    return audDataset, labelDataset\n",
    "\n",
    "def fillWithZeros(audData):\n",
    "    if(len(audData) < 88200):\n",
    "        return np.append(audData,np.zeros((88200-len(audData),1),dtype=np.float32))\n",
    "    else: #One dataset is longer\n",
    "        audData = audData[:88200]\n",
    "        return audData\n",
    "\n",
    "\n",
    "    return audData\n",
    "\n",
    "def labelTrans(labelString):\n",
    "    if(labelString == 'siren'):\n",
    "        return 0\n",
    "    elif(labelString == 'street_music'):\n",
    "        return 1\n",
    "    elif (labelString == 'drilling'):\n",
    "        return 2\n",
    "    elif (labelString == 'dog_bark'):\n",
    "        return 3\n",
    "    elif (labelString == 'children_playing'):\n",
    "        return 4\n",
    "    elif (labelString == 'gun_shot'):\n",
    "        return 5\n",
    "    elif (labelString == 'engine_idling'):\n",
    "        return 6\n",
    "    elif (labelString == 'air_conditioner'):\n",
    "        return 7\n",
    "    elif (labelString == 'jackhammer'):\n",
    "        return 8\n",
    "    elif (labelString == 'car_horn'):\n",
    "        return 9\n",
    "\n",
    "\n",
    "\n",
    "audList,labelList = csvToAudioList('C:/Users/manud/Documents/atml19/UrbanSound8K.csv','C:/Users/manud/Documents/atml19/audio/fold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, data_audio, data_label):\n",
    "\n",
    "        self.data_set = np.array(data_audio)\n",
    "        self.data_label1 = np.array(data_label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_set)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data_entry = self.data_set[index]\n",
    "        data_entry = torch.from_numpy(data_entry).reshape(4,int(len(self.data_set[index])/4))\n",
    "        data_lab = torch.from_numpy(np.array([self.data_label1[index]]))\n",
    "\n",
    "        return data_entry, data_lab.long()\n",
    "\n",
    "\n",
    "split_refList = int(len(audList)*0.8)\n",
    "split_refListSec = int(len(audList)*0.9)\n",
    "train_audList, val_audList,test_audList = audList[:split_refList], audList[split_refList:split_refListSec], audList[split_refListSec:]\n",
    "train_labelList, val_labelList,test_labelList = labelList[:split_refList], labelList[split_refList:split_refListSec], labelList[split_refListSec:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConvNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(SimpleConvNet, self).__init__()\n",
    "           \n",
    "        self.conv_layer1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=4, out_channels=16, kernel_size=1, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.conv_layer2 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.conv_layer3 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d((1))\n",
    "        )\n",
    "\n",
    "        self.linear_layer = nn.Sequential(\n",
    "            nn.Linear(64, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.conv_layer1(input)\n",
    "        output = self.conv_layer2(output)\n",
    "        output = self.conv_layer3(output)\n",
    "        \n",
    "        output = output.view(input.size(0), -1)\n",
    "        output = self.linear_layer(output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=4, out_channels=16, kernel_size=1, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.AdaptiveAvgPool1d(1)\n",
    "\n",
    "        )\n",
    "        self.linear_layer = nn.Sequential(\n",
    "            nn.Linear(64, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.conv_layers(input)\n",
    "        output = output.view(input.size(0), -1)\n",
    "        output = self.linear_layer(output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataset = AudioDataset(train_audList,train_labelList)\n",
    "valDataset = AudioDataset(val_audList,val_labelList)\n",
    "testDataset = AudioDataset(test_audList,test_labelList)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(trainDataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "val_dataloader = torch.utils.data.DataLoader(valDataset, batch_size=32, num_workers=0)\n",
    "test_dataloader = torch.utils.data.DataLoader(testDataset, batch_size=32, num_workers=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: unspecified launch failure",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-01f1c4c47418>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStepLR\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimizerRES\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataloaderRes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mval_dataloaderRes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mRES\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizerRES\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[0mtestLoss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestAcc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRES\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_dataloaderRes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The accuracy on the testdata is \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestAcc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"%\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\atml19\\utils_train.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(train_dataloader, val_dataloader, model, optimizer, loss_fn, n_epochs, scheduler)\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mlearning_rates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m         \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m         \u001b[0mval_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[0mtrain_losses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\atml19\\utils_train.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, optimizer, loss_fn, print_every)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m#         if iteration % print_every == 0:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;31m#             print('Training iteration {}: loss {:.4f}'.format(iteration, loss.item()))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[0mn_correct\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100.0\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mn_correct\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: unspecified launch failure"
     ]
    }
   ],
   "source": [
    "class AudioDatasetRes(Dataset):\n",
    "    def __init__(self, data_audio, data_label):\n",
    "\n",
    "        self.data_set = np.array(data_audio)\n",
    "        self.data_label1 = np.array(data_label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_set)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data_entry = self.data_set[index]\n",
    "        data_entry = torch.from_numpy(data_entry).reshape(4,1,int(len(self.data_set[index])/4))\n",
    "        data_lab = torch.from_numpy(np.array([self.data_label1[index]]))\n",
    "        \n",
    "        return data_entry, data_lab.long()\n",
    "\n",
    "\n",
    "trainDatasetRes = AudioDatasetRes(train_audList,train_labelList)\n",
    "valDatasetRes = AudioDatasetRes(val_audList,val_labelList)\n",
    "testDatasetRes = AudioDatasetRes(test_audList,test_labelList)\n",
    "\n",
    "train_dataloaderRes = torch.utils.data.DataLoader(trainDatasetRes, batch_size=32, shuffle=True, num_workers=0)\n",
    "val_dataloaderRes = torch.utils.data.DataLoader(valDatasetRes, batch_size=32, num_workers=0)\n",
    "test_dataloaderRes = torch.utils.data.DataLoader(testDatasetRes, batch_size=32, num_workers=0)\n",
    "\n",
    "\n",
    "epochs = 8\n",
    "RES = models.resnet18()\n",
    "\n",
    "RES.conv1 = nn.Conv2d(4, 64, kernel_size=1, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "optimizerRES = torch.optim.Adam(RES.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer=optimizerRES, step_size=10, gamma=0.1)\n",
    "fit(train_dataloaderRes,val_dataloaderRes,RES,optimizerRES,loss_fn,epochs, scheduler )\n",
    "testLoss, testAcc = test(RES, val_dataloaderRes, loss_fn)\n",
    "print(\"The accuracy on the testdata is \" + str(testAcc) + \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25: train_loss: 2.2253, train_accuracy: 15.6478, val_loss: 2.3583, val_accuracy: 18.5567\n",
      "Epoch 2/25: train_loss: 2.0892, train_accuracy: 21.7037, val_loss: 2.3335, val_accuracy: 19.8167\n",
      "Epoch 3/25: train_loss: 1.9038, train_accuracy: 27.4016, val_loss: 2.2046, val_accuracy: 27.9496\n",
      "Epoch 4/25: train_loss: 1.8196, train_accuracy: 31.0523, val_loss: 2.2194, val_accuracy: 29.3242\n",
      "Epoch 5/25: train_loss: 1.7189, train_accuracy: 35.6335, val_loss: 2.0602, val_accuracy: 28.6369\n",
      "Epoch 6/25: train_loss: 1.6582, train_accuracy: 37.0079, val_loss: 2.0559, val_accuracy: 31.9588\n",
      "Epoch 7/25: train_loss: 1.5943, train_accuracy: 39.8712, val_loss: 2.0587, val_accuracy: 32.5315\n",
      "Epoch 8/25: train_loss: 1.5557, train_accuracy: 42.2047, val_loss: 2.1368, val_accuracy: 32.7606\n",
      "Epoch 9/25: train_loss: 1.5290, train_accuracy: 43.0494, val_loss: 1.9926, val_accuracy: 35.9679\n",
      "Epoch 10/25: train_loss: 1.4988, train_accuracy: 45.2684, val_loss: 2.1664, val_accuracy: 33.7915\n",
      "Epoch 11/25: train_loss: 1.4390, train_accuracy: 47.2441, val_loss: 2.0527, val_accuracy: 34.2497\n",
      "Epoch 12/25: train_loss: 1.4255, train_accuracy: 48.5755, val_loss: 2.0575, val_accuracy: 34.7079\n",
      "Epoch 13/25: train_loss: 1.4200, train_accuracy: 48.6328, val_loss: 2.0588, val_accuracy: 36.0825\n",
      "Epoch 14/25: train_loss: 1.4179, train_accuracy: 48.5755, val_loss: 2.0055, val_accuracy: 36.6552\n",
      "Epoch 15/25: train_loss: 1.4126, train_accuracy: 49.3343, val_loss: 2.0264, val_accuracy: 36.8843\n",
      "Epoch 16/25: train_loss: 1.4122, train_accuracy: 49.8067, val_loss: 2.0596, val_accuracy: 36.1970\n",
      "Epoch 17/25: train_loss: 1.4084, train_accuracy: 49.6349, val_loss: 2.0044, val_accuracy: 36.3116\n",
      "Epoch 18/25: train_loss: 1.4039, train_accuracy: 49.5204, val_loss: 2.0502, val_accuracy: 36.9989\n",
      "Epoch 19/25: train_loss: 1.4024, train_accuracy: 49.9213, val_loss: 2.0592, val_accuracy: 35.1661\n",
      "Epoch 20/25: train_loss: 1.3976, train_accuracy: 50.0931, val_loss: 2.0355, val_accuracy: 35.2806\n",
      "Epoch 21/25: train_loss: 1.3901, train_accuracy: 50.5225, val_loss: 2.0321, val_accuracy: 36.7698\n",
      "Epoch 22/25: train_loss: 1.3901, train_accuracy: 50.6084, val_loss: 2.0281, val_accuracy: 36.8843\n",
      "Epoch 23/25: train_loss: 1.3874, train_accuracy: 50.8232, val_loss: 2.0258, val_accuracy: 36.7698\n",
      "Epoch 24/25: train_loss: 1.3886, train_accuracy: 50.7230, val_loss: 2.0308, val_accuracy: 36.7698\n",
      "Epoch 25/25: train_loss: 1.3880, train_accuracy: 50.7230, val_loss: 2.0409, val_accuracy: 37.1134\n",
      "[0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 5e-05, 5e-05, 5e-05, 5e-05, 5e-05]\n",
      "The accuracy on the testdata is 44.05034324942792%\n"
     ]
    }
   ],
   "source": [
    "epochs = 25\n",
    "\n",
    "SCN = SimpleConvNet()\n",
    "\n",
    "\n",
    "optimizerSCN = torch.optim.Adam(SCN.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer=optimizerSCN, step_size=10, gamma=0.1)\n",
    "fit(train_dataloader,val_dataloader,SCN,optimizerSCN,loss_fn,epochs, scheduler )\n",
    "testLoss, testAcc = test(SCN, test_dataloader, loss_fn)\n",
    "print(\"The accuracy on the testdata is \" + str(testAcc) + \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25: train_loss: 1.7334, train_accuracy: 35.6478, val_loss: 2.1843, val_accuracy: 31.3860\n",
      "Epoch 2/25: train_loss: 1.5222, train_accuracy: 43.8082, val_loss: 2.8044, val_accuracy: 26.2314\n",
      "Epoch 3/25: train_loss: 1.4250, train_accuracy: 47.1868, val_loss: 2.1841, val_accuracy: 34.9370\n",
      "Epoch 4/25: train_loss: 1.3581, train_accuracy: 50.3794, val_loss: 2.6924, val_accuracy: 32.8751\n",
      "Epoch 5/25: train_loss: 1.3083, train_accuracy: 52.4266, val_loss: 2.8161, val_accuracy: 32.3024\n",
      "Epoch 6/25: train_loss: 1.2487, train_accuracy: 54.3880, val_loss: 2.2441, val_accuracy: 29.8969\n",
      "Epoch 7/25: train_loss: 1.2161, train_accuracy: 56.6070, val_loss: 2.4473, val_accuracy: 35.5097\n",
      "Epoch 8/25: train_loss: 1.1731, train_accuracy: 57.9671, val_loss: 2.1733, val_accuracy: 31.6151\n",
      "Epoch 9/25: train_loss: 1.1420, train_accuracy: 59.3271, val_loss: 2.0919, val_accuracy: 36.8843\n",
      "Epoch 10/25: train_loss: 1.1130, train_accuracy: 60.7015, val_loss: 2.6222, val_accuracy: 30.6987\n",
      "Epoch 11/25: train_loss: 1.0124, train_accuracy: 64.9248, val_loss: 2.0696, val_accuracy: 40.6644\n",
      "Epoch 12/25: train_loss: 0.9745, train_accuracy: 66.7573, val_loss: 2.0669, val_accuracy: 40.7789\n",
      "Epoch 13/25: train_loss: 0.9555, train_accuracy: 66.7860, val_loss: 2.2368, val_accuracy: 36.0825\n",
      "Epoch 14/25: train_loss: 0.9523, train_accuracy: 67.6593, val_loss: 2.1294, val_accuracy: 40.6644\n",
      "Epoch 15/25: train_loss: 0.9297, train_accuracy: 67.8597, val_loss: 2.2255, val_accuracy: 38.4880\n",
      "Epoch 16/25: train_loss: 0.9231, train_accuracy: 68.6471, val_loss: 2.2195, val_accuracy: 43.2990\n",
      "Epoch 17/25: train_loss: 0.9118, train_accuracy: 68.8905, val_loss: 2.0694, val_accuracy: 40.3207\n",
      "Epoch 18/25: train_loss: 0.9172, train_accuracy: 68.6042, val_loss: 2.2679, val_accuracy: 40.0916\n",
      "Epoch 19/25: train_loss: 0.9080, train_accuracy: 69.2484, val_loss: 2.0992, val_accuracy: 41.4662\n",
      "Epoch 20/25: train_loss: 0.8981, train_accuracy: 69.1482, val_loss: 2.1654, val_accuracy: 43.9863\n",
      "Epoch 21/25: train_loss: 0.8914, train_accuracy: 69.0193, val_loss: 2.1914, val_accuracy: 38.7171\n",
      "Epoch 22/25: train_loss: 0.8744, train_accuracy: 70.5941, val_loss: 2.1588, val_accuracy: 39.9771\n",
      "Epoch 23/25: train_loss: 0.8782, train_accuracy: 69.8354, val_loss: 2.1194, val_accuracy: 42.2680\n",
      "Epoch 24/25: train_loss: 0.8762, train_accuracy: 70.0358, val_loss: 2.1612, val_accuracy: 40.6644\n",
      "Epoch 25/25: train_loss: 0.8848, train_accuracy: 70.3221, val_loss: 2.0988, val_accuracy: 39.6334\n",
      "[0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 5e-05, 5e-05, 5e-05, 5e-05, 5e-05]\n",
      "The accuracy on the testdata is 52.974828375286044%\n"
     ]
    }
   ],
   "source": [
    "epochs = 25\n",
    "CN = ConvNet()\n",
    "\n",
    "optimizerCN = torch.optim.Adam(CN.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer=optimizerCN, step_size=10, gamma=0.1)\n",
    "fit(train_dataloader,val_dataloader,CN,optimizerCN,loss_fn,epochs, scheduler )\n",
    "testLoss, testAcc = test(CN, test_dataloader, loss_fn)\n",
    "print(\"The accuracy on the testdata is \" + str(testAcc) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
