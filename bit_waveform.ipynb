{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import random\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import adabound\n",
    "\n",
    "from trainer_helper import Trainer_Helper\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "random.seed(23)\n",
    "torch.manual_seed(23)\n",
    "if device == \"cuda:0\":\n",
    "    torch.cuda.manual_seed(23)\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"UrbanSound8K/bitmap/\"\n",
    "num_classes = 10\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bitmap_loader(path):\n",
    "    with np.load(path) as data:\n",
    "        #print(data['arr_0'].shape)\n",
    "        data_len = data['arr_0'].shape[1]\n",
    "        arr = data['arr_0']\n",
    "        if data_len > 22050:\n",
    "            data_len = 22050\n",
    "            arr = arr[:,0:22050]\n",
    "        assert arr.shape[1] <= 22050\n",
    "        #try:\n",
    "        arr = np.pad(arr, ((0, 0), (0, 22050-data_len)), 'constant')\n",
    "        #except:\n",
    "        #    print(data['arr_0'].shape)\n",
    "        #    print(arr.shape)\n",
    "        #arr = data['arr_0']\n",
    "        result = []\n",
    "        for row in arr:\n",
    "            unpacked_row = np.unpackbits(row)\n",
    "            result.append(unpacked_row)\n",
    "\n",
    "        #return torch.FloatTensor(result)\n",
    "        return np.array(result)\n",
    "\n",
    "\n",
    "train_dataset = datasets.DatasetFolder(data_dir + 'train/', loader=bitmap_loader, extensions='npz')\n",
    "val_dataset = datasets.DatasetFolder(data_dir + 'val/', loader=bitmap_loader, extensions='npz')\n",
    "test_dataset = datasets.DatasetFolder(data_dir + 'test/', loader=bitmap_loader, extensions='npz')\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, pin_memory =True, shuffle=True, num_workers=4)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, pin_memory=True, num_workers=4)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=uint8), 0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, hidden_size=256, lstm_layers=2, cnn_start_channels=256):\n",
    "        super(RNN, self).__init__()\n",
    "        self.name = \"CNN({})_LSTM({}_hidden_{})\".format(cnn_start_channels, lstm_layers, cnn_start_channels)\n",
    "\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            # input.size: 16x176400\n",
    "            nn.Conv1d(in_channels=16, out_channels=cnn_start_channels, kernel_size=30, stride=10),\n",
    "            # output: 64 x 17638\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(cnn_start_channels),\n",
    "            # output 64x17638\n",
    "\n",
    "            nn.Conv1d(in_channels=cnn_start_channels, out_channels=2*cnn_start_channels, kernel_size=30, stride=10),\n",
    "            # output: 256 x 1762\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(2*cnn_start_channels),\n",
    "            # output: 256 x 1762\n",
    "\n",
    "            nn.Conv1d(in_channels=2*cnn_start_channels, out_channels=4*cnn_start_channels, kernel_size=30, stride=10),\n",
    "            # output: 256 x 175\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(4*cnn_start_channels),\n",
    "            # output: 256 x 175\n",
    "        )\n",
    "\n",
    "        self.rnn = nn.LSTM(input_size=4*cnn_start_channels,\n",
    "                            hidden_size=hidden_size, dropout=0.2,\n",
    "                            num_layers=lstm_layers)\n",
    "\n",
    "        #self.rnn = nn.GRU(input_size=4*cnn_start_channels,\n",
    "        #                    hidden_size=hidden_size, dropout=0.2,\n",
    "        #                    num_layers=lstm_layers)\n",
    "\n",
    "        self.fc = nn.Linear(hidden_size, 10)\n",
    "\n",
    "    def forward(self, inputs, hidden = None):\n",
    "        output = self.conv_layers(inputs)\n",
    "\n",
    "        output = output.transpose(1, 2).transpose(0, 1)\n",
    "\n",
    "        output = torch.tanh(output)\n",
    "        output, hidden = self.rnn(output, hidden)\n",
    "\n",
    "        output = self.fc(output[-1, :, :])\n",
    "\n",
    "        return output, hidden\n",
    "\n",
    "    def get_name(self):\n",
    "        return self.name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch: 1  Avg accuracy: 0.33 Avg loss: 1.72\n",
      "Validation Results - Epoch: 1  Avg accuracy: 0.31 Avg loss: 1.80\n",
      "Training Results - Epoch: 2  Avg accuracy: 0.40 Avg loss: 1.60\n",
      "Validation Results - Epoch: 2  Avg accuracy: 0.35 Avg loss: 1.70\n",
      "Training Results - Epoch: 3  Avg accuracy: 0.45 Avg loss: 1.52\n",
      "Validation Results - Epoch: 3  Avg accuracy: 0.37 Avg loss: 1.84\n",
      "Training Results - Epoch: 4  Avg accuracy: 0.50 Avg loss: 1.35\n",
      "Validation Results - Epoch: 4  Avg accuracy: 0.39 Avg loss: 1.64\n",
      "Training Results - Epoch: 5  Avg accuracy: 0.50 Avg loss: 1.40\n",
      "Validation Results - Epoch: 5  Avg accuracy: 0.39 Avg loss: 1.76\n",
      "Training Results - Epoch: 6  Avg accuracy: 0.57 Avg loss: 1.16\n",
      "Validation Results - Epoch: 6  Avg accuracy: 0.40 Avg loss: 1.81\n",
      "Training Results - Epoch: 7  Avg accuracy: 0.66 Avg loss: 0.96\n",
      "Validation Results - Epoch: 7  Avg accuracy: 0.41 Avg loss: 1.53\n",
      "Training Results - Epoch: 8  Avg accuracy: 0.72 Avg loss: 0.78\n",
      "Validation Results - Epoch: 8  Avg accuracy: 0.41 Avg loss: 2.00\n",
      "Training Results - Epoch: 9  Avg accuracy: 0.73 Avg loss: 0.74\n",
      "Validation Results - Epoch: 9  Avg accuracy: 0.42 Avg loss: 1.99\n",
      "Training Results - Epoch: 10  Avg accuracy: 0.81 Avg loss: 0.55\n",
      "Validation Results - Epoch: 10  Avg accuracy: 0.48 Avg loss: 1.75\n",
      "Training Results - Epoch: 11  Avg accuracy: 0.88 Avg loss: 0.40\n",
      "Validation Results - Epoch: 11  Avg accuracy: 0.46 Avg loss: 1.91\n",
      "Training Results - Epoch: 12  Avg accuracy: 0.91 Avg loss: 0.29\n",
      "Validation Results - Epoch: 12  Avg accuracy: 0.45 Avg loss: 2.17\n",
      "Training Results - Epoch: 13  Avg accuracy: 0.93 Avg loss: 0.22\n",
      "Validation Results - Epoch: 13  Avg accuracy: 0.49 Avg loss: 2.16\n",
      "Training Results - Epoch: 14  Avg accuracy: 0.94 Avg loss: 0.18\n",
      "Validation Results - Epoch: 14  Avg accuracy: 0.47 Avg loss: 2.49\n",
      "Training Results - Epoch: 15  Avg accuracy: 0.94 Avg loss: 0.18\n",
      "Validation Results - Epoch: 15  Avg accuracy: 0.45 Avg loss: 2.73\n",
      "Training Results - Epoch: 16  Avg accuracy: 0.88 Avg loss: 0.37\n",
      "Validation Results - Epoch: 16  Avg accuracy: 0.42 Avg loss: 2.97\n",
      "Training Results - Epoch: 17  Avg accuracy: 0.98 Avg loss: 0.08\n",
      "Validation Results - Epoch: 17  Avg accuracy: 0.50 Avg loss: 2.79\n",
      "Training Results - Epoch: 18  Avg accuracy: 0.98 Avg loss: 0.07\n",
      "Validation Results - Epoch: 18  Avg accuracy: 0.46 Avg loss: 3.06\n",
      "Training Results - Epoch: 19  Avg accuracy: 0.97 Avg loss: 0.10\n",
      "Validation Results - Epoch: 19  Avg accuracy: 0.47 Avg loss: 3.01\n",
      "Training Results - Epoch: 20  Avg accuracy: 0.98 Avg loss: 0.07\n",
      "Validation Results - Epoch: 20  Avg accuracy: 0.44 Avg loss: 3.16\n",
      "Training Results - Epoch: 21  Avg accuracy: 0.98 Avg loss: 0.05\n",
      "Validation Results - Epoch: 21  Avg accuracy: 0.44 Avg loss: 3.20\n",
      "Training Results - Epoch: 22  Avg accuracy: 0.99 Avg loss: 0.03\n",
      "Validation Results - Epoch: 22  Avg accuracy: 0.48 Avg loss: 3.05\n"
     ]
    }
   ],
   "source": [
    "model = RNN()\n",
    "\n",
    "run_name = datetime.datetime.now().strftime(\"%Y.%m.%d.%H.%M.%S\")\n",
    "run_name = 'rnn-adabound-lr0-001'\n",
    "\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "optimizer = adabound.AdaBound(model.parameters(), lr=1e-3, final_lr=0.1)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "trainer = Trainer_Helper(run_name, device)\n",
    "trainer.setup_dataloader(train_dataloader, val_dataloader, test_dataloader)\n",
    "trainer.train_rnn(model, optimizer, criterion, 100)\n",
    "\n",
    "# Use a CosineAnnelingScheduler with SGD optimizer. Similar result as Adabound but much slower.\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "#lr = 1e-3\n",
    "#lr_handler = CosineAnnealingScheduler(optimizer, 'lr', lr, lr*100, len(train_dataloader), cycle_mult=2)\n",
    "#trainer.add_event_handler(Events.ITERATION_COMPLETED, lr_handler)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda_venv",
   "language": "python",
   "name": "cuda_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
