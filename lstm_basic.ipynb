{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_sequence\n",
    "import time\n",
    "import copy\n",
    "\n",
    "from helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.1.0\n",
      "Torchvision Version:  0.2.2\n",
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "data_dir = \"data/train/bitmap\"\n",
    "num_epochs = 10\n",
    "\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Datasets and Dataloaders...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'air_conditioner': 0,\n",
       " 'car_horn': 1,\n",
       " 'children_playing': 2,\n",
       " 'dog_bark': 3,\n",
       " 'drilling': 4,\n",
       " 'engine_idling': 5,\n",
       " 'gun_shot': 6,\n",
       " 'jackhammer': 7,\n",
       " 'siren': 8,\n",
       " 'street_music': 9}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "def bitmap_loader(path):\n",
    "    with np.load(path) as data:\n",
    "        data_len = data['arr_0'].shape[1]\n",
    "        arr = np.pad(data['arr_0'], ((0, 0), (0, 22050-data_len)), 'constant')\n",
    "        result = []\n",
    "        for row in arr:\n",
    "            unpacked_row = np.unpackbits(row)\n",
    "            result.append(unpacked_row)\n",
    "\n",
    "        return np.array(result)\n",
    "\n",
    "\n",
    "bitmap_dataset = datasets.DatasetFolder(data_dir, loader=bitmap_loader, extensions='npz')\n",
    "\n",
    "validation_split = 0.2\n",
    "random_seed = 42\n",
    "\n",
    "dataset_size = len(bitmap_dataset)\n",
    "split = int(validation_split * dataset_size)\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "indices = np.random.permutation(dataset_size)\n",
    "\n",
    "train_size = int(0.8 * dataset_size)\n",
    "val_size = dataset_size - train_size\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(bitmap_dataset, [train_size, val_size])\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "dataloaders_dict = {}\n",
    "dataloaders_dict['train'] = train_dataloader\n",
    "dataloaders_dict['val'] = val_dataloader\n",
    "\n",
    "bitmap_dataset.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, hidden_size=256, lstm_layers=2, cnn_start_channels=256):\n",
    "        super(RNN, self).__init__()\n",
    "        self.name = \"CNN({})_LSTM({}_hidden_{})\".format(cnn_start_channels, lstm_layers, cnn_start_channels)\n",
    "\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            # input.size: 16x176400\n",
    "            nn.Conv1d(in_channels=16, out_channels=cnn_start_channels, kernel_size=30, stride=10),\n",
    "            # output: 64 x 17638\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(cnn_start_channels),\n",
    "            # output 64x17638\n",
    "\n",
    "            nn.Conv1d(in_channels=cnn_start_channels, out_channels=2*cnn_start_channels, kernel_size=30, stride=10),\n",
    "            # output: 256 x 1762\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(2*cnn_start_channels),\n",
    "            # output: 256 x 1762\n",
    "\n",
    "            nn.Conv1d(in_channels=2*cnn_start_channels, out_channels=4*cnn_start_channels, kernel_size=30, stride=10),\n",
    "            # output: 256 x 175\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(4*cnn_start_channels),\n",
    "            # output: 256 x 175\n",
    "        )\n",
    "\n",
    "        self.rnn = nn.LSTM(input_size=4*cnn_start_channels,\n",
    "                            hidden_size=hidden_size, dropout=0.2,\n",
    "                            num_layers=lstm_layers)\n",
    "\n",
    "        #self.rnn = nn.GRU(input_size=4*cnn_start_channels,\n",
    "        #                    hidden_size=hidden_size, dropout=0.2,\n",
    "        #                    num_layers=lstm_layers)\n",
    "\n",
    "        self.fc = nn.Linear(hidden_size, 10)\n",
    "\n",
    "    def forward(self, inputs, hidden):\n",
    "        output = self.conv_layers(inputs)\n",
    "\n",
    "        output = output.transpose(1, 2).transpose(0, 1)\n",
    "\n",
    "        output = torch.tanh(output)\n",
    "        output, hidden = self.rnn(output, hidden)\n",
    "\n",
    "        output = self.fc(output[-1, :, :])\n",
    "\n",
    "        return output, hidden\n",
    "\n",
    "    def get_name(self):\n",
    "        return self.name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, scheduler=None, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "    val_loss_history = []\n",
    "\n",
    "    train_acc_history = []\n",
    "    train_loss_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best_epoch = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device, dtype=torch.float)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs, hidden = model(inputs, None)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_epoch = epoch\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "                val_loss_history.append(epoch_loss)\n",
    "\n",
    "            if phase == 'train':\n",
    "                if scheduler is not None:\n",
    "                    scheduler.step()\n",
    "                train_acc_history.append(epoch_acc)\n",
    "                train_loss_history.append(epoch_loss)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, best_epoch, (train_loss_history, val_loss_history, train_acc_history, val_acc_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN()\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01) # 0.005\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 1.1502 Acc: 0.5846\n",
      "val Loss: 1.3212 Acc: 0.5281\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 1.1286 Acc: 0.5853\n",
      "val Loss: 1.2250 Acc: 0.5842\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 1.0830 Acc: 0.5984\n",
      "val Loss: 1.1925 Acc: 0.5805\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 1.0765 Acc: 0.6044\n",
      "val Loss: 1.2111 Acc: 0.5805\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 1.0731 Acc: 0.6132\n",
      "val Loss: 1.2143 Acc: 0.5787\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 1.0629 Acc: 0.6166\n",
      "val Loss: 1.2316 Acc: 0.5860\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 1.0302 Acc: 0.6357\n",
      "val Loss: 1.2404 Acc: 0.5621\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 1.0321 Acc: 0.6251\n",
      "val Loss: 1.1579 Acc: 0.6081\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 1.0115 Acc: 0.6421\n",
      "val Loss: 1.1211 Acc: 0.6210\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 0.9894 Acc: 0.6447\n",
      "val Loss: 1.1408 Acc: 0.6072\n",
      "\n",
      "Training complete in 15m 44s\n",
      "Best val Acc: 0.620975\n"
     ]
    }
   ],
   "source": [
    "#for g in optimizer.param_groups:\n",
    "#    g['lr'] = 1.0\n",
    "\n",
    "model, best_epoch, hist = train_model(model, dataloaders_dict, criterion, optimizer, scheduler=scheduler, num_epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lr_finder import *\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-7, weight_decay=1e-2)\n",
    "lr_finder = LRFinder(model, optimizer, criterion, device=device)\n",
    "lr_finder.range_test(dataloaders_dict['train'], end_lr=100, num_iter=100, step_mode=\"exp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_finder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(n_epochs, train_losses, val_losses, train_accuracies, val_accuracies):\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(n_epochs), train_losses)\n",
    "    plt.plot(np.arange(n_epochs), val_losses)\n",
    "    plt.legend(['train_loss', 'val_loss'])\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss value')\n",
    "    plt.title('Train/val loss');\n",
    "\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(n_epochs), train_accuracies)\n",
    "    plt.plot(np.arange(n_epochs), val_accuracies)\n",
    "    plt.legend(['train_acc', 'val_acc'])\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.title('Train/val accuracy')\n",
    "\n",
    "\n",
    "plot(len(hist[0]), *hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_filepath = './saved_models/{}_{:.0f}'.format(model.get_name(), 100*hist[3][best_epoch])\n",
    "\n",
    "plot_train_history(len(hist[0]), model_filepath, *hist)\n",
    "\n",
    "torch.save({\n",
    "    'epoch': best_epoch,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': hist[1][best_epoch]\n",
    "}, model_filepath)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda_venv",
   "language": "python",
   "name": "cuda_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
